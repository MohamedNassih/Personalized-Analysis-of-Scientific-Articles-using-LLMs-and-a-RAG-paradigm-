# -*- coding: utf-8 -*-
"""Collecte_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12mhcmbP8sv8zxDzt4LgnEdP4_anhKt8w
"""

!pip install selenium

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# 
# # Add debian buster
# cat > /etc/apt/sources.list.d/debian.list <<'EOF'
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main
# EOF
# 
# # Add keys
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A
# 
# apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg
# apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg
# apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg
# 
# # Prefer debian repo for chromium* packages only
# # Note the double-blank lines between entries
# cat > /etc/apt/preferences.d/chromium.pref << 'EOF'
# Package: *
# Pin: release a=eoan
# Pin-Priority: 500
# 
# 
# Package: *
# Pin: origin "deb.debian.org"
# Pin-Priority: 300
# 
# 
# Package: chromium*
# Pin: origin "deb.debian.org"
# Pin-Priority: 700
# EOF
#

!apt-get update
!apt-get install chromium chromium-driver

def web_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--verbose")
    options.add_argument('--no-sandbox')
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    options.add_argument("--window-size=1920, 1200")
    options.add_argument('--disable-dev-shm-usage')
    driver = webdriver.Chrome(options=options)
    return driver

import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time

!pip install requests
!pip install PyPDF2
!pip install PyMuPDF

driver = web_driver()
driver.get('https://arxiv.org/search/?searchtype=all&query=ai&abstracts=show&size=200&order=-announced_date_first&start=0')

import requests
import fitz  # PyMuPDF

def extract_pdf_content_from_url(pdf_url):
    response = requests.get(pdf_url)
    pdf_document = fitz.open("pdf", stream=response.content)
    content = ""

    for page in pdf_document:
        content += page.get_text()

    pdf_document.close()

    return content

article_titles=[]
article_authors=[]
article_abstract=[]
article_pub_date=[]
article_link=[]
article_pdf_link=[]
article_content=[]

for i in range(0,14774,200):
    driver.get('https://arxiv.org/search/?searchtype=all&query=ai&abstracts=show&size=200&order=-announced_date_first&start={}'.format(i))
    article_titles_=driver.find_elements("xpath",'//*[@class="title is-5 mathjax"]')
    article_authors_=driver.find_elements("xpath",'//*[@class="authors"]')
    article_abstract_=driver.find_elements("xpath",'//*[@class="abstract mathjax"]')
    article_pub_date_=driver.find_elements("xpath",'//p[@class="is-size-7"]')
    article_link_=driver.find_elements("xpath",'//*[@class="list-title is-inline-block"]/a')
    article_pdf_link_=driver.find_elements("xpath",'//*[@class="list-title is-inline-block"]/span/a[1]')
    for k in range(len(article_pdf_link_)):
        article_titles.append(article_titles_[k].text)
        article_authors.append(article_authors_[k].text)
        article_abstract.append(article_abstract_[k].text)
        article_pub_date.append(article_pub_date_[k].text)
        article_link.append(article_link_[k].get_attribute('href'))
        article_pdf_link.append(article_pdf_link_[k].get_attribute('href'))
        article_content.append(extract_pdf_content_from_url(article_pdf_link[k]))
    break

articles=[]
for i in range(len(article_titles)):
    article_infos={}
    article_infos['Title']=article_titles[i]
    article_infos['Authors']=article_authors[i]
    article_infos['Abstract']=article_abstract[i]
    article_infos['Submitted']=article_pub_date[i]
    article_infos['Link']=article_link[i]
    article_infos['PDF_Link']=article_pdf_link[i]
    article_infos['Content']=article_content[i]
    articles.append(article_infos)
articles

df=pd.DataFrame(articles,columns=['Title','Authors','Abstract','Submitted','Link','PDF_Link','Content'])
df

import os

# Create the directory if it doesn't exist
directory = "dossier_Echantillons"
if not os.path.exists(directory):
    os.makedirs(directory)

# Save each "Content" to a separate text file
for index, row in df.iterrows():
    filename = os.path.join(directory, f"article_{index + 1}.txt")
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(row['Content'])

from google.colab import files
!zip -r /content/dossier_Echantillons.zip /content/dossier_Echantillons
files.download("/content/dossier_Echantillons.zip")